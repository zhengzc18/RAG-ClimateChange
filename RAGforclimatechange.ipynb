{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connection"
      ],
      "metadata": {
        "id": "rZlrGjEO3vB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install langchain-openai\n",
        "!pip install langchain-openai tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YOTKQLr0jMaN",
        "outputId": "a483a5d0-eeba-49cb-a4d5-1347fcdb16f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.2.7)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.1.77)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (1.26.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
            "  Downloading greenlet-3.0.3-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (2.4)\n",
            "Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_10_9_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.0.3-cp312-cp312-macosx_11_0_universal2.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.1/273.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: greenlet, SQLAlchemy, langchain-text-splitters, langchain\n",
            "Successfully installed SQLAlchemy-2.0.30 greenlet-3.0.3 langchain-0.2.5 langchain-text-splitters-0.2.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMRC2IvpmDg2",
        "outputId": "ed4f5fae-1506-446c-84be-926f02467ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (5.15.0)\r\n",
            "Requirement already satisfied: pytz in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from neo4j) (2023.3.post1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.graphs import Neo4jGraph\n",
        "\n",
        "graph = Neo4jGraph(url=\"bolt://localhost:7687\", username= \"neo4j\", password=\"isoon2299\")"
      ],
      "metadata": {
        "id": "jTNcGjXjjGFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain-openai"
      ],
      "metadata": {
        "id": "-64O8OWUJ79v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "m3x5O2X8jLQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs.graph_document import (\n",
        "    Node as BaseNode,\n",
        "    Relationship as BaseRelationship,\n",
        "    GraphDocument,\n",
        ")\n",
        "from langchain.schema import Document\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain.pydantic_v1 import Field, BaseModel"
      ],
      "metadata": {
        "id": "xjXIXGCybXLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Property(BaseModel):\n",
        "  \"\"\"A single property consisting of key and value\"\"\"\n",
        "  key: str = Field(..., description=\"key\")\n",
        "  value: str = Field(..., description=\"value\")"
      ],
      "metadata": {
        "id": "kfrotLrHbzJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(BaseNode):\n",
        "  properties: Optional[List[Property]] = Field(\n",
        "      None, description=\"List of relationship properties\"\n",
        "  )"
      ],
      "metadata": {
        "id": "3PxufZ9EcJpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relationship(BaseRelationship):\n",
        "    properties: Optional[List[Property]] = Field(\n",
        "        None, description=\"List of relationship properties\"\n",
        "    )"
      ],
      "metadata": {
        "id": "sH5te2KIcvo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeGraph(BaseModel):\n",
        "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
        "    nodes: List[Node] = Field(\n",
        "        ..., description=\"List of nodes in the knowledge graph\")\n",
        "    rels: List[Relationship] = Field(\n",
        "        ..., description=\"List of relationships in the knowledge graph\"\n",
        "    )"
      ],
      "metadata": {
        "id": "qAqrLkZ0cT65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_property_key(s: str) -> str:\n",
        "    words = s.split()\n",
        "    if not words:\n",
        "        return s\n",
        "    first_word = words[0].lower()\n",
        "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
        "    return \"\".join([first_word] + capitalized_words)"
      ],
      "metadata": {
        "id": "lY15w4wbdAge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def props_to_dict(props) -> dict:\n",
        "    \"\"\"Convert properties to a dictionary.\"\"\"\n",
        "    properties = {}\n",
        "    if not props:\n",
        "      return properties\n",
        "    for p in props:\n",
        "        properties[format_property_key(p.key)] = p.value\n",
        "    return properties"
      ],
      "metadata": {
        "id": "FcaV_PRwdXwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_to_base_node(node: Node) -> BaseNode:\n",
        "    \"\"\"Map the KnowledgeGraph Node to the base Node.\"\"\"\n",
        "    properties = props_to_dict(node.properties) if node.properties else {}\n",
        "    # Add name property for better Cypher statement generation\n",
        "    properties[\"name\"] = node.id.title()\n",
        "    return BaseNode(\n",
        "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
        "    )"
      ],
      "metadata": {
        "id": "xCkJt2_WdpG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
        "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
        "    source = map_to_base_node(rel.source)\n",
        "    target = map_to_base_node(rel.target)\n",
        "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
        "    return BaseRelationship(\n",
        "        source=source, target=target, type=rel.type, properties=properties\n",
        "    )"
      ],
      "metadata": {
        "id": "OvXIiJCmeN3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chains.openai_functions import (\n",
        "    create_openai_fn_chain,\n",
        "    create_structured_output_chain,\n",
        ")\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-CQbOjrwUwFyNrGHMiEgfT3BlbkFJIAKRts2U70Qs71nFGvx2\"\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
        "\n",
        "def get_extraction_chain(\n",
        "    allowed_nodes: Optional[List[str]] = None,\n",
        "    allowed_rels: Optional[List[str]] = None\n",
        "    ):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [(\n",
        "          \"system\",\n",
        "          f\"\"\"# Knowledge Graph Instructions for GPT-4\n",
        "## 1. Overview\n",
        "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
        "- **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
        "- The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
        "## 2. Labeling Nodes\n",
        "- **Consistency**: Ensure you use basic or elementary types for node labels.\n",
        "  - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
        "- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
        "{'- **Allowed Node Labels:**' + \", \".join(allowed_nodes) if allowed_nodes else \"\"}\n",
        "{'- **Allowed Relationship Types**:' + \", \".join(allowed_rels) if allowed_rels else \"\"}\n",
        "## 3. Handling Numerical Data and Dates\n",
        "- Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
        "- **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
        "- **Property Format**: Properties must be in a key-value format.\n",
        "- **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
        "- **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
        "## 4. Coreference Resolution\n",
        "- **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
        "If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),\n",
        "always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\n",
        "Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\n",
        "## 5. Strict Compliance\n",
        "Adhere to the rules strictly. Non-compliance will result in termination.\n",
        "          \"\"\"),\n",
        "            (\"human\", \"Use the given format to extract information from the following input: {input}\"),\n",
        "            (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
        "        ])\n",
        "    return create_structured_output_chain(KnowledgeGraph, llm, prompt, verbose=False)"
      ],
      "metadata": {
        "id": "EiVX8eF9edKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides the general instructions, I have also added the option to limit which node or relationship types should be extracted from text. You'll see through examples why this might come in handy. We have the Neo4j connection and LLM prompt ready, which means we can define the information extraction pipeline as a single function."
      ],
      "metadata": {
        "id": "TlUa42b4e2Lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_store_graph(\n",
        "    document: Document,\n",
        "    nodes:Optional[List[str]] = None,\n",
        "    rels:Optional[List[str]]=None) -> None:\n",
        "    # Extract graph data using OpenAI functions\n",
        "    extract_chain = get_extraction_chain(nodes, rels)\n",
        "    data = extract_chain.invoke(document.page_content)['function']\n",
        "    # Construct a graph document\n",
        "    graph_document = GraphDocument(\n",
        "      nodes = [map_to_base_node(node) for node in data.nodes],\n",
        "      relationships = [map_to_base_relationship(rel) for rel in data.rels],\n",
        "      source = document\n",
        "    )\n",
        "    # Store information into a graph\n",
        "    graph.add_graph_documents([graph_document])"
      ],
      "metadata": {
        "id": "6TTLzKtseuJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "AbRBGBwctAAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "rvVVA3PywZ-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n"
      ],
      "metadata": {
        "id": "XzsyIFRZYD7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import TokenTextSplitter"
      ],
      "metadata": {
        "id": "Y0kcLC4gYyE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "94KgFMCDWvUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Neo4jVector"
      ],
      "metadata": {
        "id": "69iQyikH53Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2"
      ],
      "metadata": {
        "id": "CZzXvB8d27hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_to_text(pdf_path, output_txt):\n",
        "    # Open the PDF file in read-binary mode\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        # Create a PdfReader object instead of PdfFileReader\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "        # Initialize an empty string to store the text\n",
        "        text = ''\n",
        "\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "\n",
        "    # Write the extracted text to a text file\n",
        "    with open(output_txt, 'w', encoding='utf-8') as txt_file:\n",
        "        txt_file.write(text)\n"
      ],
      "metadata": {
        "id": "VIcf9dUBzykF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"/Users/jaesoon/Desktop/Data/OneDegreeWar.pdf\"\n",
        "\n",
        "    output_txt = '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'\n",
        "\n",
        "    pdf_to_text(pdf_path, output_txt)\n",
        "\n",
        "    print(\"PDF converted to text successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voXmrNcg2sfA",
        "outputId": "d6c36d9a-3ae8-46c3-890b-e9585318e8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF converted to text successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from PyPDF2 import PdfReader\n",
        "#reader = PdfReader(\"/Users/jaesoon/Desktop/Data/OneDegreeWar.pdf\")\n",
        "#number_of_pages = len(reader.pages)\n",
        "#page = reader.pages[0]\n",
        "#text = page.extract_text()"
      ],
      "metadata": {
        "id": "-19u6GtJ3nR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"/Users/jaesoon/Desktop/Data/OneDegreeWar.txt\")"
      ],
      "metadata": {
        "id": "OFJ0jZDQwpXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loader.load()\n",
        "text_splitter = TokenTextSplitter(chunk_size=90, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "text_splitter.split_documents(documents)[:10]"
      ],
      "metadata": {
        "id": "arMObHHGw8sQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2094d41f-b968-4e03-8c70-6c5019856f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='The one degree war plan\\nJorgen Randers\\nNorwegian School of Management BI, Oslo, Norway, and\\nPaul Gilding\\nProgramme for Sustainability Leadership, University of Cambridge,\\nSydney, Australia\\nAbstract\\nPurpose – The purpose of this paper is to present the idea of a global crisis plan that will be\\ndemanded when global society ﬁnally decides that the climate challenge is a', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content=' real threat, requiring\\nimmediate and strong policy action at the super-national level. The authors believe that this demand\\nwill arise before 2020, and the authors hope that this paper will encourage others to improve on the\\nplan.\\nDesign/methodology/approach – The paper seeks to achieve the purpose by presenting the ﬁrst\\ndraft of such a plan – “The one degree war plan” – in rather', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content=' concrete terms, and estimating\\n(in quantitative terms) the expected reduction in climate gas emissions that would result from\\nimplementing the crisis plan.\\nFindings – The paper ﬁnds that it is surprisingly simple to develop a plan which will reduce global\\nemissions by 50 per cent in ﬁve years. It also seems possible to lower global emissions to zero in the\\nensuing decade, and then run negative emissions', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content=' of 6 GtCO2e/year for the rest of the century (through\\ncarbon capture in various forms). The result, using the C-ROADS climate model, is to keep the\\ntemperature rise in 2100 below þ18C above the pre-industrial level. Much work needs to assure these\\nconclusions.\\nPractical implications – The authors argue that public awareness of the dangers associated with\\nclimate change will increase over the', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content=' next decade, to the level where it is perceived to be a signiﬁcant\\nthreat to global economic and geopolitical stability. The public will then demand emergency action to\\ncut global climate gas emissions. The authors argue that such emergency action ought to be based on a\\nwell-prepared crisis response plan that seeks to keep global warming below þ18C over pre-industrial\\nlevels. The paper presents a draft of the crisis', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content=' response plan and encourages further efforts to improve\\nthe plan.\\nSocial implications – The social value of having a well-considered and well-prepared climate crisis\\nplan in place once the public demand immediate climate action from their politicians, can hardly be\\noverestimated.\\nOriginality/value – To the authors’ knowledge, no similar crisis plan has been published.\\nKeywords Environmental management, Global warming, Climatology\\n', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content='Paper type Research paper\\nIntroduction\\nIt is like belonging to a secret society. Conversations held in quiet places, in cafes, bars\\nand academic halls. Conversations held with furrowed brows and worried eyes.\\nConversations that sometimes give you goose bumps and shivers, and a sense of the\\nsurreal – is this conversation really happening?\\nThis is what it is felt like over the past few years, to spend', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content=' time with some of the world’s\\nleading thinkers and scientists on issues around climate change and sustainability.\\nIn public, this group generally puts a positive, while still urgent interpretation of\\ntheir views. The general public position is: “we face serious risks, potentially catastrophic,The current issue and full text archive of this journal is available at\\nwww.emeraldinsight.com/2041-2568.htm\\nJ', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content='GR\\n1,1\\n170\\nJournal of Global Responsibility\\nVol. 1 No. 1, 2010\\npp. 170-188\\nqEmerald Group Publishing Limited\\n2041-2568\\nDOI 10.1108/20412561011039762if we don’t act urgently and strongly”. Of course, “If we don’t act” is the key qualiﬁ', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'}),\n",
              " Document(page_content='er,\\nwith very few prepared in public at least, to cross that dreaded line or to use those words\\n“it’s too late”.\\nBut in private, often late at night, when we reﬂect on what we really think and\\nwonder if the battle is lost, it is a different conversation. The talk goes to the potential\\nfor self-reinforcing runaway loops and for civilisation', metadata={'source': '/Users/jaesoon/Desktop/Data/OneDegreeWar.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, d in tqdm(enumerate(docs), total=len(documents)):\n",
        "  extract_and_store_graph(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-UMHh49e_8D",
        "outputId": "f9d95fd7-939e-4c6a-c20f-fd997b97fcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|                                                     | 0/1 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `create_structured_output_chain` was deprecated in LangChain 0.1.1 and will be removed in 0.3.0. Use ChatOpenAI.with_structured_output instead.\n",
            "  warn_deprecated(\n",
            "150it [21:36,  8.65s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "prhwcrEn5bHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"openai-chat.py\"\n",
        "sys.path.append(os.path.abspath(py_file_location))"
      ],
      "metadata": {
        "id": "VCcXabxGG_e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-proj-CQbOjrwUwFyNrGHMiEgfT3BlbkFJIAKRts2U70Qs71nFGvx2'"
      ],
      "metadata": {
        "id": "_lFAwfqKHaSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = Neo4jVector.from_documents(\n",
        "    docs, OpenAIEmbeddings(), url=\"bolt://localhost:7687\", username= \"neo4j\", password=\"isoon2299\"\n",
        ")"
      ],
      "metadata": {
        "id": "2vmYsDcbIygM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me about the global climate change\"\n",
        "results = db.similarity_search(query, k=1)\n",
        "print(results[0].page_content)"
      ],
      "metadata": {
        "id": "02TStl3-Iy3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f316111-7d6b-4421-aac7-0221a0065c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lobal clim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rk-gbLAdNQYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}